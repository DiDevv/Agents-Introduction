{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando minha Api Key da OpenAI que se encontra na minha variável de ambiente\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trata da capacidade dos modelos de poderem utilizar fontes externas como APIs para gerarem respostas mais precisas aos usuários, evitando problemas de alucinação do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função básica de chamada de modelo e obtenção de respostas. Vale ressaltar que o modelo utilizado deve\n",
    "# Suportar as Functions Callings.\n",
    "def get_completion (messages, model=\"gpt-3.5-turbo-1106\", temperature=0, tools=None, tool_choice=None):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        tools=tools,\n",
    "        tool_choice=tool_choice\n",
    "    )\n",
    "    return response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo uma Dummy Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função fictícia para testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essa função servirá como ferramenta para o modelo\n",
    "def get_current_weather(location, unit=\"celsius\"):\n",
    "    \"\"\"Pega a temperatura atual em uma determinada localização\"\"\"\n",
    "    weather = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"30\",\n",
    "        \"unit\": unit,\n",
    "    }\n",
    "    return json.dumps(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a função em uma variável Tools que será passada para o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\":\"function\",\n",
    "        \"function\": {\n",
    "            \"name\":\"get_current_weather\",\n",
    "            \"description\":\"Pega a temperatura atual em uma determinada localização\",\n",
    "            \"parameters\": {\n",
    "                \"type\":\"object\",\n",
    "                \"properties\":{\n",
    "                    \"location\": {\n",
    "                        \"type\":\"string\",\n",
    "                        \"description\":\"A cidade e o estado, e.g. Goiana, PE\"\n",
    "                    },\n",
    "                    \"unit\":{\n",
    "                        \"type\":\"string\",\n",
    "                        \"enum\":[\"celsius\",\"fahrenheit\"]\n",
    "                    }\n",
    "                },\n",
    "                \"required\":[\"location\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o prompt\n",
    "\n",
    "messages = [\n",
    "    {\"role\":\"user\",\n",
    "     \"content\":\"Qual a temperatura em Londrina por favor?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_zo7uqFAb3ahj0jWUOnxd8jAV', function=Function(arguments='{\"location\":\"Londrina\",\"unit\":\"celsius\"}', name='get_current_weather'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "# Aqui é possível verificar como o modelo escolheu os parâmetros da função com base no que escrevi\n",
    "# no Prompt\n",
    "response = get_completion(messages, tools=tools)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraindo os argumentos da função\n",
    "args = json.loads(response.tool_calls[0].function.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'Londrina', 'unit': 'celsius'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": \"Londrina\", \"temperature\": \"30\", \"unit\": \"celsius\"}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controlando o comportamento do Function Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma forma de controlar o comportamento para evitar que a função seja chamada desnecessariamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\":\"user\",\n",
    "     \"content\":\"Oi, oi!\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='Olá! Como posso ajudar você hoje?', refusal=None, role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(messages, tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por padrão, o modelo decide por si só quando chamar uma tool, mas isso pode facilmente ser configurado utilizando a ferramenta de ``tool_choice`` que por padrão vem configurada como ``tool_choice=\"auto\"``.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='Olá! Como posso ajudar você hoje?', refusal=None, role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(messages, tools=tools, tool_choice=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``tool_choice=\"none\"`` não permite que o modelo use nenhuma função disponibilizada para ele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\":\"user\",\n",
    "     \"content\":\"Qual a temperatura em Londres por favor?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='Por favor, aguarde um momento enquanto verifico a temperatura atual em Londres para você.', refusal=None, role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(messages, tools=tools, tool_choice=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima é possível observar que o modelo foi forçado a não utilizar a função passada para ele anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também é possível forçar o modelo a usar uma função específica ao seu querer. Por exemplo, em uma variável tools que tem muitas funções, em determinados prompts você pode passar uma função específica para ajudar o modelo a não precisar perder tempo analizando todas as outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\":\"user\",\n",
    "     \"content\":\"Qual a temperatura em Londres por favor?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ZcV0n78N4ghqbo8skKvuqHK3', function=Function(arguments='{\"location\":\"London\",\"unit\":\"celsius\"}', name='get_current_weather'), type='function')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(messages, tools=tools, tool_choice={\"type\":\"function\", \"function\":{\"name\":\"get_current_weather\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChatBot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
